{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Yes, if $\\alpha$ is constant but sufficiently small, GD will converge to a minimizer of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "No, even if the $\\alpha$ is suffiently small, SGM still has no guarantee to converge to the minimizer of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "Yes, there exists a $\\alpha_k$ under certain conditions that makes SGM to converge to a minimizer of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "\n",
    "According to the given equation of hinge loss, we define the term $\\left< \\mathbf{w}, \\mathbf{x}_i \\right> + b$ in function $J(\\mathbf{w}, b)$ as $t_i$, thus the given empirical risk can be rewritten as:\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "J(\\mathbf{w}, b) &= \\frac{1}{n} \\sum_{i=1}^{n} (\\text{max}\\left\\{ 0, 1 - y_i t_i \\right\\}) + \\frac{\\lambda}{2} \\left\\| \\mathbf{w} \\right\\|^2 \\\\\n",
    "&= \\sum_{i=1}^{n} \\frac{1}{n} (\\text{max}\\left\\{ 0, 1 - y_i t_i \\right\\}) + \\frac{\\lambda}{2} \\left\\| \\mathbf{w} \\right\\|^2 \\\\\n",
    "&= \\sum_{i=1}^{n} \\left(\\frac{1}{n} \\text{max}\\left\\{ 0, 1 - y_i (\\left< \\mathbf{w}, \\mathbf{x}_i \\right> + b) \\right\\} + \\frac{\\lambda}{2n} \\left\\| \\mathbf{w} \\right\\|^2 \\right).\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Therefore, $J_i (\\mathbf{w}, b)$ can be interpreted as:\n",
    "$$\n",
    "J_i (\\mathbf{w}, b) = \\frac{1}{n} \\text{max}\\left\\{ 0, 1 - y_i (\\left< \\mathbf{w}, \\mathbf{x}_i \\right> + b) \\right\\} + \\frac{\\lambda}{2n} \\left\\| \\mathbf{w} \\right\\|^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\n",
    "\n",
    "Firstly, we should further rewrite $J_i$ to be more readable\n",
    "\n",
    "$$\n",
    "J_i (\\mathbf{w}, b) = \\frac{1}{n} \\text{max}\\left\\{ 0, 1 - y_i ( \\mathbf{w}^\\top \\mathbf{x}_i + b) \\right\\} + \\frac{\\lambda}{2n} \\left\\| \\mathbf{w} \\right\\|^2,\n",
    "$$\n",
    "\n",
    "subsequently, use $\\mathbf{\\theta}$ to simplifiy $J_i$\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "J_i (\\mathbf{w}, b) &= \\frac{1}{n} \\text{max}\\left\\{ 0, 1 - y_i \\mathbf{\\theta}^\\top \\tilde{\\mathbf{x}}_i \\right\\} + \\frac{\\lambda}{2n} \\left\\|\n",
    "\\begin{bmatrix}\n",
    "0 & \\\\\n",
    "  & \\mathbf{I}\n",
    "\\end{bmatrix} \\cdot \\mathbf{\\theta}\n",
    "\\right\\|^2 \\\\\n",
    "&= \\frac{1}{n} \\text{max}\\left\\{ 0, 1 - y_i \\mathbf{\\theta}^\\top \\tilde{\\mathbf{x}}_i \\right\\} + \\frac{\\lambda}{2n} \\mathbf{\\theta}^\\top\n",
    "\\begin{bmatrix}\n",
    "0 & \\\\\n",
    "  & \\mathbf{I}\n",
    "\\end{bmatrix} \\cdot \\mathbf{\\theta}\n",
    "\\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "where $\\tilde{\\mathbf{x}_i} = [1 , \\mathbf{x_i}^\\top]^\\top$. We can define $\\tilde{\\mathbf{I}} = \\begin{bmatrix}\n",
    "0 & \\\\\n",
    "  & \\mathbf{I}\n",
    "\\end{bmatrix}$ for simplicity, thus $J_i$ can be further rewritten as\n",
    "\n",
    "$$\n",
    "J_i = \\frac{1}{n} \\text{max}\\left\\{ 0, 1 - y_i \\mathbf{\\theta}^\\top \\tilde{\\mathbf{x}}_i \\right\\} + \\frac{\\lambda}{2n} \\mathbf{\\theta}^\\top \\tilde{\\mathbf{I}} \\mathbf{\\theta}\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "With the equation above, its gradient w.r.t. $\\mathbf{\\theta}$ can be given as\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_i = \n",
    "\\begin{cases}\n",
    "\\frac{1}{n}(- y_i \\tilde{\\mathbf{x}}_i + \\lambda \\tilde{\\mathbf{I}}\\mathbf{\\theta}),~\\text{if } y_i \\mathbf{\\theta}^\\top \\tilde{\\mathbf{x}}_i \\le 1 \\\\\n",
    "\\frac{\\lambda}{n} \\tilde{\\mathbf{I}}\\mathbf{\\theta}, ~ \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
