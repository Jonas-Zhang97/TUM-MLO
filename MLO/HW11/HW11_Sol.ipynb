{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "For a single step of convolution on an arbitary data point in an arbitrary channel, we have $k \\times k$ many multiplications and $k \\cdot (k-1)$ many additions, which means within a single channel, there are in total $(k^2+k(k-1))\\cdot w\\cdot h$ many calculations, and we have $c$ channels, which gives us $(k^2+k(k-1))\\cdot w\\cdot h \\cdot c$ many calculations. In $\\mathcal{O}$ notation, the computational cost should be $\\mathcal{O}(k^2whc)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "\n",
    "* Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filter the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog', 'ship']\n",
    "class_indices = {'cat': 0, 'dog': 1, 'ship': 2}\n",
    "\n",
    "def filter_classes(dataset, classes):\n",
    "    class_to_idx = {dataset.classes[i]: i for i in range(len(dataset.classes))}\n",
    "    filtered_indices = []\n",
    "    labels = []\n",
    "    for i, (_, label) in enumerate(dataset):\n",
    "        if dataset.classes[label] in classes:\n",
    "            filtered_indices.append(i)\n",
    "            labels.append(class_indices[dataset.classes[label]])\n",
    "    return torch.utils.data.Subset(dataset, filtered_indices), torch.tensor(labels)\n",
    "\n",
    "trainset_filtered, train_labels = filter_classes(trainset, class_names)\n",
    "testset_filtered, test_labels = filter_classes(testset, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remap the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class remappedDataset(Dataset):\n",
    "    def __init__(self, subset, labels):\n",
    "        self.subset = subset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.subset[idx]\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = remappedDataset(trainset_filtered, train_labels)\n",
    "test_dataset = remappedDataset(testset_filtered, test_labels)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.pooling = nn.MaxPool2d(2, 2)\n",
    "    self.linear1 = nn.Linear(5*5*16, 120)\n",
    "    self.linear2 = nn.Linear(120, 84)\n",
    "    self.linear3 = nn.Linear(84, 3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pooling(F.relu(self.conv1(x)))\n",
    "    x = self.pooling(F.relu(self.conv2(x)))\n",
    "    x = x.view(-1, 16 * 5 * 5)\n",
    "    x = F.relu(self.linear1(x))\n",
    "    x = F.relu(self.linear2(x))\n",
    "    x = self.linear3(x)\n",
    "    return x\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5714861377806092, Test Accuracy: 72.36666666666666%\n",
      "Epoch 2, Loss: 0.5367183759396275, Test Accuracy: 74.6%\n",
      "Epoch 3, Loss: 0.5090775508440255, Test Accuracy: 73.76666666666667%\n",
      "Epoch 4, Loss: 0.48291732497972745, Test Accuracy: 75.2%\n",
      "Epoch 5, Loss: 0.4585593342268529, Test Accuracy: 77.4%\n",
      "Epoch 6, Loss: 0.4344570583905714, Test Accuracy: 77.46666666666667%\n",
      "Epoch 7, Loss: 0.40506579721325736, Test Accuracy: 75.4%\n",
      "Epoch 8, Loss: 0.3847428083923165, Test Accuracy: 76.1%\n",
      "Epoch 9, Loss: 0.35653543670056725, Test Accuracy: 75.43333333333334%\n",
      "Epoch 10, Loss: 0.32142896284716793, Test Accuracy: 75.13333333333334%\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(cnn, trainloader, testloader, optimizer, \n",
    "                       loss_function, epochs=10):\n",
    "  best_accuracy = 0\n",
    "  best_model_state = None\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    cnn.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "      inputs, labels = data\n",
    "      # print(\"label: %s\", labels)\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = cnn(inputs)\n",
    "      loss = loss_function(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    # Evaluate on test data\n",
    "    cnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}, \n",
    "          Test Accuracy: {test_accuracy}%')\n",
    "\n",
    "    # Save the best model\n",
    "    if test_accuracy > best_accuracy:\n",
    "      best_accuracy = test_accuracy\n",
    "      best_model_state = cnn.state_dict()\n",
    "\n",
    "  print('Training Finished')\n",
    "  return best_model_state\n",
    "\n",
    "# Train the cnnwork and save the best model\n",
    "best_model_state = train_and_evaluate(cnn, trainloader, testloader, \n",
    "                                      optimizer, loss_function)\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model_state, './best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can observe that the convolutional neural network performs better than the simple fully connected neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\n",
    "\n",
    "* Shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class shuffledDataset(Dataset):\n",
    "    def __init__(self, original_dataset):\n",
    "        self.dataset = original_dataset\n",
    "        self.permutation = torch.randperm(3 * 32 * 32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset[index]\n",
    "        # Convert image to 1D tensor and apply the same permutation to all images\n",
    "        image_1d = image.view(-1)\n",
    "        shuffled_image_1d = image_1d[self.permutation]\n",
    "        # Convert back to original shape\n",
    "        shuffled_image = shuffled_image_1d.view(3, 32, 32)\n",
    "        return shuffled_image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "# Create shuffled datasets\n",
    "trainset_shuffled = shuffledDataset(trainset_filtered)\n",
    "testset_shuffled = shuffledDataset(testset_filtered)\n",
    "\n",
    "trainset_shuffled_remapped = remappedDataset(trainset_shuffled, train_labels)\n",
    "testset_shuffled_remapped = remappedDataset(testset_shuffled, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "trainloader_shuffled = DataLoader(trainset_shuffled_remapped, batch_size=4, \n",
    "                                  shuffle=True, num_workers=2)\n",
    "testloader_shuffled = DataLoader(testset_shuffled_remapped, batch_size=4, \n",
    "                                 shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train with shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7743579309908052, Test Accuracy: 31.966666666666665%\n",
      "Epoch 2, Loss: 0.6789236864373088, Test Accuracy: 32.666666666666664%\n",
      "Epoch 3, Loss: 0.6392491559597353, Test Accuracy: 32.5%\n",
      "Epoch 4, Loss: 0.6065750461059312, Test Accuracy: 32.8%\n",
      "Epoch 5, Loss: 0.5770396108590998, Test Accuracy: 31.833333333333332%\n",
      "Epoch 6, Loss: 0.5474726777335008, Test Accuracy: 32.7%\n",
      "Epoch 7, Loss: 0.52086586153411, Test Accuracy: 33.36666666666667%\n",
      "Epoch 8, Loss: 0.49159315741838266, Test Accuracy: 32.43333333333333%\n",
      "Epoch 9, Loss: 0.4616542441578349, Test Accuracy: 33.266666666666666%\n",
      "Epoch 10, Loss: 0.4337282149097669, Test Accuracy: 33.43333333333333%\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "best_model_state = train_and_evaluate(cnn, trainloader_shuffled, \n",
    "                                      testloader_shuffled, optimizer, \n",
    "                                      loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluation\n",
    "\n",
    "We found that the performance is lot worse, because by shuffling the pixels, we distorted the shape of original object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "\n",
    "* Implement fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCNN, self).__init__()\n",
    "        # Hidden layer with d=3*32*32 and 512 neurons\n",
    "        self.layer1 = nn.Linear(3 * 32 * 32, 512)\n",
    "        # Output layer maps number of neurons to the output dimension\n",
    "        self.layer2 = nn.Linear(512, len(class_names))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3 * 32 * 32)\n",
    "        x = F.relu(self.layer1(x)) \n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "fcnn = FCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train on shuffled set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1030349195480347, Test Accuracy: 33.7%\n",
      "Epoch 2, Loss: 1.1030349198500315, Test Accuracy: 33.7%\n",
      "Epoch 3, Loss: 1.1030349203745524, Test Accuracy: 33.7%\n",
      "Epoch 4, Loss: 1.1030349208990733, Test Accuracy: 33.7%\n",
      "Epoch 5, Loss: 1.103034920056661, Test Accuracy: 33.7%\n",
      "Epoch 6, Loss: 1.1030349197069804, Test Accuracy: 33.7%\n",
      "Epoch 7, Loss: 1.103034920835495, Test Accuracy: 33.7%\n",
      "Epoch 8, Loss: 1.1030349195162454, Test Accuracy: 33.7%\n",
      "Epoch 9, Loss: 1.1030349198818208, Test Accuracy: 33.7%\n",
      "Epoch 10, Loss: 1.1030349203109742, Test Accuracy: 33.7%\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "best_model_state = train_and_evaluate(fcnn, trainloader_shuffled, \n",
    "                                      testloader_shuffled, optimizer, \n",
    "                                      loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluation\n",
    "\n",
    "From test accuracies we noticed that the classifier is accturally randomly labeling the input, which means it cannot work properly, the reason is the same as mentioned in subtask 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
